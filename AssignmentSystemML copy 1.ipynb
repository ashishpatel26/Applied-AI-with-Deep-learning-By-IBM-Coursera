{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Sonar Example\n\nIn this Exercise you will, build a Neural Netowrk to Classify Sonar Readings as either a \"Mine\" or a \"Rock\"\n\n## Data Set Information:\n\nThe file \"sonar.mines\" contains 111 patterns obtained by bouncing sonar signals off a metal cylinder at various angles and under various conditions. The file \"sonar.rocks\" contains 97 patterns obtained from rocks under similar conditions. The transmitted sonar signal is a frequency-modulated chirp, rising in frequency. The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock. \n\nEach pattern is a set of 60 numbers in the range 0.0 to 1.0. Each number represents the energy within a particular frequency band, integrated over a certain period of time. The integration aperture for higher frequencies occur later in time, since these frequencies are transmitted later during the chirp. \n\nThe label associated with each record contains the letter \"R\" if the object is a rock and \"M\" if it is a mine (metal cylinder). The numbers in the labels are in increasing order of aspect angle, but they do not encode the angle directly.\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "source": "# Download the data\n\nWhen this command completes you will have a file \"sonar.all-data\"", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = app-20190717084711-0000\nKERNEL_ID = dbe9716d-038a-42ba-a14f-0555a263cde5\n--2019-07-17 08:47:13--  https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data\nResolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\nConnecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 87776 (86K) [application/x-httpd-php]\nSaving to: 'sonar.all-data'\n\nsonar.all-data      100%[===================>]  85.72K  --.-KB/s    in 0.07s   \n\n2019-07-17 08:47:14 (1.23 MB/s) - 'sonar.all-data' saved [87776/87776]\n\n"
                }
            ], 
            "source": "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/sonar/sonar.all-data"
        }, 
        {
            "source": "# Rename the DataFile\n\nRename the datafile to sonar.csv", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!mv sonar.all-data sonar.csv"
        }, 
        {
            "source": "# Convert Text Labels to Integers\n\nYou will create a Keras Neural Network to classify each record as a Mine or a Rock. \n\nAlthough, It is straightforward to keep the labels \"M\" or \"R\" in Keras and have working code, the goal of this exercise is to save the model and then load the model into DeepLearning4J a java framework. The Java Code to import has been prebuilt and precompiled and expects numeric labels. With that restriction in mind, convert the \"M's\" to \"0\" and the \"R's\" to \"1\" with the following commands. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 3, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!sed -i -e 's/M/0/g' sonar.csv"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "!sed -i -e 's/R/1/g' sonar.csv"
        }, 
        {
            "source": "# Verify the contents of the file.\n\nThe file has 60 features per line, followed by a label of 0 or 1. \n\nThe data is not shuffled, although for best neural network training performance shuffling would be advised. \n\nTo verify that the above conversion succeeded view the head and the tail of the file. Congratulations, if you see version 1.2.0 or higher, please continue with the notebook...", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0.0200,0.0371,0.0428,0.0207,0.0954,0.0986,0.1539,0.1601,0.3109,0.2111,0.1609,0.1582,0.2238,0.0645,0.0660,0.2273,0.3100,0.2999,0.5078,0.4797,0.5783,0.5071,0.4328,0.5550,0.6711,0.6415,0.7104,0.8080,0.6791,0.3857,0.1307,0.2604,0.5121,0.7547,0.8537,0.8507,0.6692,0.6097,0.4943,0.2744,0.0510,0.2834,0.2825,0.4256,0.2641,0.1386,0.1051,0.1343,0.0383,0.0324,0.0232,0.0027,0.0065,0.0159,0.0072,0.0167,0.0180,0.0084,0.0090,0.0032,1\r\n0.0453,0.0523,0.0843,0.0689,0.1183,0.2583,0.2156,0.3481,0.3337,0.2872,0.4918,0.6552,0.6919,0.7797,0.7464,0.9444,1.0000,0.8874,0.8024,0.7818,0.5212,0.4052,0.3957,0.3914,0.3250,0.3200,0.3271,0.2767,0.4423,0.2028,0.3788,0.2947,0.1984,0.2341,0.1306,0.4182,0.3835,0.1057,0.1840,0.1970,0.1674,0.0583,0.1401,0.1628,0.0621,0.0203,0.0530,0.0742,0.0409,0.0061,0.0125,0.0084,0.0089,0.0048,0.0094,0.0191,0.0140,0.0049,0.0052,0.0044,1\r\n0.0262,0.0582,0.1099,0.1083,0.0974,0.2280,0.2431,0.3771,0.5598,0.6194,0.6333,0.7060,0.5544,0.5320,0.6479,0.6931,0.6759,0.7551,0.8929,0.8619,0.7974,0.6737,0.4293,0.3648,0.5331,0.2413,0.5070,0.8533,0.6036,0.8514,0.8512,0.5045,0.1862,0.2709,0.4232,0.3043,0.6116,0.6756,0.5375,0.4719,0.4647,0.2587,0.2129,0.2222,0.2111,0.0176,0.1348,0.0744,0.0130,0.0106,0.0033,0.0232,0.0166,0.0095,0.0180,0.0244,0.0316,0.0164,0.0095,0.0078,1\r\n0.0100,0.0171,0.0623,0.0205,0.0205,0.0368,0.1098,0.1276,0.0598,0.1264,0.0881,0.1992,0.0184,0.2261,0.1729,0.2131,0.0693,0.2281,0.4060,0.3973,0.2741,0.3690,0.5556,0.4846,0.3140,0.5334,0.5256,0.2520,0.2090,0.3559,0.6260,0.7340,0.6120,0.3497,0.3953,0.3012,0.5408,0.8814,0.9857,0.9167,0.6121,0.5006,0.3210,0.3202,0.4295,0.3654,0.2655,0.1576,0.0681,0.0294,0.0241,0.0121,0.0036,0.0150,0.0085,0.0073,0.0050,0.0044,0.0040,0.0117,1\r\n0.0762,0.0666,0.0481,0.0394,0.0590,0.0649,0.1209,0.2467,0.3564,0.4459,0.4152,0.3952,0.4256,0.4135,0.4528,0.5326,0.7306,0.6193,0.2032,0.4636,0.4148,0.4292,0.5730,0.5399,0.3161,0.2285,0.6995,1.0000,0.7262,0.4724,0.5103,0.5459,0.2881,0.0981,0.1951,0.4181,0.4604,0.3217,0.2828,0.2430,0.1979,0.2444,0.1847,0.0841,0.0692,0.0528,0.0357,0.0085,0.0230,0.0046,0.0156,0.0031,0.0054,0.0105,0.0110,0.0015,0.0072,0.0048,0.0107,0.0094,1\r\n0.0286,0.0453,0.0277,0.0174,0.0384,0.0990,0.1201,0.1833,0.2105,0.3039,0.2988,0.4250,0.6343,0.8198,1.0000,0.9988,0.9508,0.9025,0.7234,0.5122,0.2074,0.3985,0.5890,0.2872,0.2043,0.5782,0.5389,0.3750,0.3411,0.5067,0.5580,0.4778,0.3299,0.2198,0.1407,0.2856,0.3807,0.4158,0.4054,0.3296,0.2707,0.2650,0.0723,0.1238,0.1192,0.1089,0.0623,0.0494,0.0264,0.0081,0.0104,0.0045,0.0014,0.0038,0.0013,0.0089,0.0057,0.0027,0.0051,0.0062,1\r\n0.0317,0.0956,0.1321,0.1408,0.1674,0.1710,0.0731,0.1401,0.2083,0.3513,0.1786,0.0658,0.0513,0.3752,0.5419,0.5440,0.5150,0.4262,0.2024,0.4233,0.7723,0.9735,0.9390,0.5559,0.5268,0.6826,0.5713,0.5429,0.2177,0.2149,0.5811,0.6323,0.2965,0.1873,0.2969,0.5163,0.6153,0.4283,0.5479,0.6133,0.5017,0.2377,0.1957,0.1749,0.1304,0.0597,0.1124,0.1047,0.0507,0.0159,0.0195,0.0201,0.0248,0.0131,0.0070,0.0138,0.0092,0.0143,0.0036,0.0103,1\r\n0.0519,0.0548,0.0842,0.0319,0.1158,0.0922,0.1027,0.0613,0.1465,0.2838,0.2802,0.3086,0.2657,0.3801,0.5626,0.4376,0.2617,0.1199,0.6676,0.9402,0.7832,0.5352,0.6809,0.9174,0.7613,0.8220,0.8872,0.6091,0.2967,0.1103,0.1318,0.0624,0.0990,0.4006,0.3666,0.1050,0.1915,0.3930,0.4288,0.2546,0.1151,0.2196,0.1879,0.1437,0.2146,0.2360,0.1125,0.0254,0.0285,0.0178,0.0052,0.0081,0.0120,0.0045,0.0121,0.0097,0.0085,0.0047,0.0048,0.0053,1\r\n0.0223,0.0375,0.0484,0.0475,0.0647,0.0591,0.0753,0.0098,0.0684,0.1487,0.1156,0.1654,0.3833,0.3598,0.1713,0.1136,0.0349,0.3796,0.7401,0.9925,0.9802,0.8890,0.6712,0.4286,0.3374,0.7366,0.9611,0.7353,0.4856,0.1594,0.3007,0.4096,0.3170,0.3305,0.3408,0.2186,0.2463,0.2726,0.1680,0.2792,0.2558,0.1740,0.2121,0.1099,0.0985,0.1271,0.1459,0.1164,0.0777,0.0439,0.0061,0.0145,0.0128,0.0145,0.0058,0.0049,0.0065,0.0093,0.0059,0.0022,1\r\n0.0164,0.0173,0.0347,0.0070,0.0187,0.0671,0.1056,0.0697,0.0962,0.0251,0.0801,0.1056,0.1266,0.0890,0.0198,0.1133,0.2826,0.3234,0.3238,0.4333,0.6068,0.7652,0.9203,0.9719,0.9207,0.7545,0.8289,0.8907,0.7309,0.6896,0.5829,0.4935,0.3101,0.0306,0.0244,0.1108,0.1594,0.1371,0.0696,0.0452,0.0620,0.1421,0.1597,0.1384,0.0372,0.0688,0.0867,0.0513,0.0092,0.0198,0.0118,0.0090,0.0223,0.0179,0.0084,0.0068,0.0032,0.0035,0.0056,0.0040,1\r\n"
                }
            ], 
            "source": "!head sonar.csv"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "0.0238,0.0318,0.0422,0.0399,0.0788,0.0766,0.0881,0.1143,0.1594,0.2048,0.2652,0.3100,0.2381,0.1918,0.1430,0.1735,0.1781,0.2852,0.5036,0.6166,0.7616,0.8125,0.7793,0.8788,0.8813,0.9470,1.0000,0.9739,0.8446,0.6151,0.4302,0.3165,0.2869,0.2017,0.1206,0.0271,0.0580,0.1262,0.1072,0.1082,0.0360,0.1197,0.2061,0.2054,0.1878,0.2047,0.1716,0.1069,0.0477,0.0170,0.0186,0.0096,0.0071,0.0084,0.0038,0.0026,0.0028,0.0013,0.0035,0.0060,0\r\n0.0116,0.0744,0.0367,0.0225,0.0076,0.0545,0.1110,0.1069,0.1708,0.2271,0.3171,0.2882,0.2657,0.2307,0.1889,0.1791,0.2298,0.3715,0.6223,0.7260,0.7934,0.8045,0.8067,0.9173,0.9327,0.9562,1.0000,0.9818,0.8684,0.6381,0.3997,0.3242,0.2835,0.2413,0.2321,0.1260,0.0693,0.0701,0.1439,0.1475,0.0438,0.0469,0.1476,0.1742,0.1555,0.1651,0.1181,0.0720,0.0321,0.0056,0.0202,0.0141,0.0103,0.0100,0.0034,0.0026,0.0037,0.0044,0.0057,0.0035,0\r\n0.0131,0.0387,0.0329,0.0078,0.0721,0.1341,0.1626,0.1902,0.2610,0.3193,0.3468,0.3738,0.3055,0.1926,0.1385,0.2122,0.2758,0.4576,0.6487,0.7154,0.8010,0.7924,0.8793,1.0000,0.9865,0.9474,0.9474,0.9315,0.8326,0.6213,0.3772,0.2822,0.2042,0.2190,0.2223,0.1327,0.0521,0.0618,0.1416,0.1460,0.0846,0.1055,0.1639,0.1916,0.2085,0.2335,0.1964,0.1300,0.0633,0.0183,0.0137,0.0150,0.0076,0.0032,0.0037,0.0071,0.0040,0.0009,0.0015,0.0085,0\r\n0.0335,0.0258,0.0398,0.0570,0.0529,0.1091,0.1709,0.1684,0.1865,0.2660,0.3188,0.3553,0.3116,0.1965,0.1780,0.2794,0.2870,0.3969,0.5599,0.6936,0.7969,0.7452,0.8203,0.9261,0.8810,0.8814,0.9301,0.9955,0.8576,0.6069,0.3934,0.2464,0.1645,0.1140,0.0956,0.0080,0.0702,0.0936,0.0894,0.1127,0.0873,0.1020,0.1964,0.2256,0.1814,0.2012,0.1688,0.1037,0.0501,0.0136,0.0130,0.0120,0.0039,0.0053,0.0062,0.0046,0.0045,0.0022,0.0005,0.0031,0\r\n0.0272,0.0378,0.0488,0.0848,0.1127,0.1103,0.1349,0.2337,0.3113,0.3997,0.3941,0.3309,0.2926,0.1760,0.1739,0.2043,0.2088,0.2678,0.2434,0.1839,0.2802,0.6172,0.8015,0.8313,0.8440,0.8494,0.9168,1.0000,0.7896,0.5371,0.6472,0.6505,0.4959,0.2175,0.0990,0.0434,0.1708,0.1979,0.1880,0.1108,0.1702,0.0585,0.0638,0.1391,0.0638,0.0581,0.0641,0.1044,0.0732,0.0275,0.0146,0.0091,0.0045,0.0043,0.0043,0.0098,0.0054,0.0051,0.0065,0.0103,0\r\n0.0187,0.0346,0.0168,0.0177,0.0393,0.1630,0.2028,0.1694,0.2328,0.2684,0.3108,0.2933,0.2275,0.0994,0.1801,0.2200,0.2732,0.2862,0.2034,0.1740,0.4130,0.6879,0.8120,0.8453,0.8919,0.9300,0.9987,1.0000,0.8104,0.6199,0.6041,0.5547,0.4160,0.1472,0.0849,0.0608,0.0969,0.1411,0.1676,0.1200,0.1201,0.1036,0.1977,0.1339,0.0902,0.1085,0.1521,0.1363,0.0858,0.0290,0.0203,0.0116,0.0098,0.0199,0.0033,0.0101,0.0065,0.0115,0.0193,0.0157,0\r\n0.0323,0.0101,0.0298,0.0564,0.0760,0.0958,0.0990,0.1018,0.1030,0.2154,0.3085,0.3425,0.2990,0.1402,0.1235,0.1534,0.1901,0.2429,0.2120,0.2395,0.3272,0.5949,0.8302,0.9045,0.9888,0.9912,0.9448,1.0000,0.9092,0.7412,0.7691,0.7117,0.5304,0.2131,0.0928,0.1297,0.1159,0.1226,0.1768,0.0345,0.1562,0.0824,0.1149,0.1694,0.0954,0.0080,0.0790,0.1255,0.0647,0.0179,0.0051,0.0061,0.0093,0.0135,0.0063,0.0063,0.0034,0.0032,0.0062,0.0067,0\r\n0.0522,0.0437,0.0180,0.0292,0.0351,0.1171,0.1257,0.1178,0.1258,0.2529,0.2716,0.2374,0.1878,0.0983,0.0683,0.1503,0.1723,0.2339,0.1962,0.1395,0.3164,0.5888,0.7631,0.8473,0.9424,0.9986,0.9699,1.0000,0.8630,0.6979,0.7717,0.7305,0.5197,0.1786,0.1098,0.1446,0.1066,0.1440,0.1929,0.0325,0.1490,0.0328,0.0537,0.1309,0.0910,0.0757,0.1059,0.1005,0.0535,0.0235,0.0155,0.0160,0.0029,0.0051,0.0062,0.0089,0.0140,0.0138,0.0077,0.0031,0\r\n0.0303,0.0353,0.0490,0.0608,0.0167,0.1354,0.1465,0.1123,0.1945,0.2354,0.2898,0.2812,0.1578,0.0273,0.0673,0.1444,0.2070,0.2645,0.2828,0.4293,0.5685,0.6990,0.7246,0.7622,0.9242,1.0000,0.9979,0.8297,0.7032,0.7141,0.6893,0.4961,0.2584,0.0969,0.0776,0.0364,0.1572,0.1823,0.1349,0.0849,0.0492,0.1367,0.1552,0.1548,0.1319,0.0985,0.1258,0.0954,0.0489,0.0241,0.0042,0.0086,0.0046,0.0126,0.0036,0.0035,0.0034,0.0079,0.0036,0.0048,0\r\n0.0260,0.0363,0.0136,0.0272,0.0214,0.0338,0.0655,0.1400,0.1843,0.2354,0.2720,0.2442,0.1665,0.0336,0.1302,0.1708,0.2177,0.3175,0.3714,0.4552,0.5700,0.7397,0.8062,0.8837,0.9432,1.0000,0.9375,0.7603,0.7123,0.8358,0.7622,0.4567,0.1715,0.1549,0.1641,0.1869,0.2655,0.1713,0.0959,0.0768,0.0847,0.2076,0.2505,0.1862,0.1439,0.1470,0.0991,0.0041,0.0154,0.0116,0.0181,0.0146,0.0129,0.0047,0.0039,0.0061,0.0040,0.0036,0.0061,0.0115,0\r\n"
                }
            ], 
            "source": "!tail sonar.csv"
        }, 
        {
            "source": "# Build a Neural Network\n\nBuild a Keras Neural Network to Process the data file. By training a Neural Network we are feeding the network the features and asking it to make a prediction of which class of object those readings are from. \n\nWe will build a Feed Forward Neural Network using Keras Sequential Model. \n\nFirst some imports", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 7, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "Using TensorFlow backend.\n"
                }
            ], 
            "source": "import numpy\nimport pandas\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom keras.utils import np_utils"
        }, 
        {
            "source": "# Set Random Seed\n\n\nNeural Networks begin by defining a computation grid with random weights applied to each initial calculation. \n\nFor repeatable results setting a random seed guarantees that the second run will be the same as the first.\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 8, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# fix random seed for reproducibility\nseed = 7\nnumpy.random.seed(seed)"
        }, 
        {
            "source": "# Load the data into a pandas dataframe and Split into Features and Labels\n\nThe first 60 fields are measurements from the sonar, the last field is the Label\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 9, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# load dataset\ndataframe = pandas.read_csv(\"sonar.csv\", header=None)\ndataset = dataframe.values\n# split into input (X) and output (Y) variables\nX = dataset[:,0:60].astype(float)\nY = dataset[:,60]"
        }, 
        {
            "source": "# Encode Labels\n\nThe following code converts the Labels to integers, this section would actually work on the unmodified dataset containing \"M\" or \"R\" for labels, so in this case the step is redundant. \n\nThe Code also takes the integers and converts to one-hot, or dummy encoding. \n\nGiven n labels dummy encoding creates an array of length n.\nThe array will have a \"1\" value corresponding to the label and all ther values will be \"0\"\n\nFor this example with 2 labels, dummy encoding will make the following conversion. \n\nOriginal Data\n\n```\n0\n1\n0\n```\n\nDummy Encoded\n\n```\n1,0\n0,1\n1,0\n```\n\nTo verify you can uncomment the line. \n\n```\nprint(dummy_y)\n```\n\n \n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 11, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "[[0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [0. 1.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]\n [1. 0.]]\n"
                }
            ], 
            "source": "# encode class values as integers\nencoder = LabelEncoder()\nencoder.fit(Y)\nencoded_Y = encoder.transform(Y)\n\n# convert integers to dummy variables (hot encoded)\ndummy_y = np_utils.to_categorical(encoded_Y)\nprint(dummy_y)"
        }, 
        {
            "source": "# Build a model\n\nYour code here, in this case you are on your own to build a working Neural Network. \n\nYou can review the Keras section for examples. \n\nYou are free to decide the depth and features of the Neural Network. \n\nNote however, the first Layer has to have input_dim = 60 to correspond to the number of features and \nthe last layer has to have 2 nodes to correspond to the number of labels.\n\nHow will you know you have a good model? \n\nAccuracy levels of about .80 can be expected with this dataset.\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 37, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model =  Sequential()  # Instantiate sequential model\nmodel.add(Dense(64, input_dim = 60, kernel_initializer='normal', activation='relu'))\nmodel.add(Dense(2, kernel_initializer='normal', activation='sigmoid'))"
        }, 
        {
            "source": "# Compile the Model and Train\n\nModify the following cell and set your number of epochs and your batch size. \n\nDepending on your model it may train in 20 epochs or it may take 40, or it may not train at all. \n\nReplace the \"***Your VALUE HERE**\" with a numeric value. \n\nIf your loss function is not decreasing then your model is not training, modify your model and try again. \n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 39, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Epoch 1/20\n208/208 [==============================] - 1s 5ms/step - loss: 0.5624 - acc: 0.8125\nEpoch 2/20\n208/208 [==============================] - 0s 63us/step - loss: 0.5547 - acc: 0.7091\nEpoch 3/20\n208/208 [==============================] - 0s 62us/step - loss: 0.5454 - acc: 0.7236\nEpoch 4/20\n208/208 [==============================] - 0s 64us/step - loss: 0.5366 - acc: 0.8005\nEpoch 5/20\n208/208 [==============================] - 0s 62us/step - loss: 0.5305 - acc: 0.8125\nEpoch 6/20\n208/208 [==============================] - 0s 62us/step - loss: 0.5221 - acc: 0.7933\nEpoch 7/20\n208/208 [==============================] - 0s 65us/step - loss: 0.5159 - acc: 0.7764\nEpoch 8/20\n208/208 [==============================] - 0s 64us/step - loss: 0.5103 - acc: 0.8125\nEpoch 9/20\n208/208 [==============================] - 0s 62us/step - loss: 0.5021 - acc: 0.8101\nEpoch 10/20\n208/208 [==============================] - 0s 66us/step - loss: 0.4951 - acc: 0.7957\nEpoch 11/20\n208/208 [==============================] - 0s 59us/step - loss: 0.4906 - acc: 0.7837\nEpoch 12/20\n208/208 [==============================] - 0s 60us/step - loss: 0.4863 - acc: 0.8173\nEpoch 13/20\n208/208 [==============================] - 0s 58us/step - loss: 0.4793 - acc: 0.8245\nEpoch 14/20\n208/208 [==============================] - 0s 58us/step - loss: 0.4733 - acc: 0.8197\nEpoch 15/20\n208/208 [==============================] - 0s 59us/step - loss: 0.4706 - acc: 0.7981\nEpoch 16/20\n208/208 [==============================] - 0s 56us/step - loss: 0.4657 - acc: 0.8221\nEpoch 17/20\n208/208 [==============================] - 0s 85us/step - loss: 0.4614 - acc: 0.8269\nEpoch 18/20\n208/208 [==============================] - 0s 164us/step - loss: 0.4570 - acc: 0.8293\nEpoch 19/20\n208/208 [==============================] - 0s 123us/step - loss: 0.4537 - acc: 0.8149\nEpoch 20/20\n208/208 [==============================] - 0s 63us/step - loss: 0.4496 - acc: 0.8197\n"
                }, 
                {
                    "execution_count": 39, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "<keras.callbacks.History at 0x7f70a17eb4a8>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# Compile model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X, dummy_y, epochs=20, batch_size=32)"
        }, 
        {
            "source": "# Save your Model\n\nYour Model will be loaded into dl4j and run in a Spark context. A saved model includes the weights and the computation graph needed for either further training or inference. In this example we will load the model into dl4j and pass it our datafile and evaluate the accuracy of the model in dl4j running in spark. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 40, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "model.save('my_modelx.h5')"
        }, 
        {
            "source": "# Verify your model has saved\n\nThe ls command should show your model in the local directory of this notebook. ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 41, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "dl4j-snapshot.jar  logs  my_modelx.h5  sonar.csv  spark-events\tuser-libs\r\n"
                }
            ], 
            "source": "!ls"
        }, 
        {
            "source": "# Run your code in DL4J on Spark\n\n\nDL4J has a KerasModelImport feature. Java code has been written and compiled that will import a keras model, run the model on a spark cluster. \n\nYou can view the code here.\n\nhttps://github.com/maxpumperla/dl4j_coursera/blob/master/src/main/java/skymind/dsx/KerasImportCSVSparkRunner.java\n\nThis Jar has the compiled class. \n\nhttps://github.com/maxpumperla/dl4j_coursera/releases/download/v0.4/dl4j-snapshot.jar\n\n\n###  \n\nThe class KerasImportCSVSparkRunner takes the following command line options, \n\n* indexLabel\n    * Column in the data file containing Labels\n    * Labels must be numeric\n* train\n    * Set to true or false\n    * true: perform training using provided data file\n    * false: perform evaluation using provided data file\n* numClasses \n    * number of classes\n* modelFileName\n    * Saved h5 archive of your Keras Model\n* dataFileName \n    * DataFile to run training/evaluation with\n\n\n\n\n", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 42, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "--2019-07-17 09:09:17--  https://github.com/maxpumperla/dl4j_coursera/releases/download/v0.4/dl4j-snapshot.jar\nResolving github.com (github.com)... 140.82.114.4\nConnecting to github.com (github.com)|140.82.114.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://github-production-release-asset-2e65be.s3.amazonaws.com/113966420/3472050e-f84b-11e7-90f0-d69fe0bedce0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190717%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190717T090922Z&X-Amz-Expires=300&X-Amz-Signature=de92cbc3cfacb6a7c2681760b81de5aff36190e7bed693de32f9e1e9795a4ce3&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddl4j-snapshot.jar&response-content-type=application%2Foctet-stream [following]\n--2019-07-17 09:09:22--  https://github-production-release-asset-2e65be.s3.amazonaws.com/113966420/3472050e-f84b-11e7-90f0-d69fe0bedce0?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20190717%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190717T090922Z&X-Amz-Expires=300&X-Amz-Signature=de92cbc3cfacb6a7c2681760b81de5aff36190e7bed693de32f9e1e9795a4ce3&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Ddl4j-snapshot.jar&response-content-type=application%2Foctet-stream\nResolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.114.67\nConnecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.114.67|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 486534267 (464M) [application/octet-stream]\nSaving to: 'dl4j-snapshot.jar.1'\n\ndl4j-snapshot.jar.1 100%[===================>] 464.00M  45.0MB/s    in 11s     \n\n2019-07-17 09:09:35 (41.5 MB/s) - 'dl4j-snapshot.jar.1' saved [486534267/486534267]\n\n"
                }
            ], 
            "source": "!wget https://github.com/maxpumperla/dl4j_coursera/releases/download/v0.4/dl4j-snapshot.jar"
        }, 
        {
            "source": "# Run your code in Spark\n\nThe output from Spark is rather verbose, lots of notices and warnings. \n\nThis code will take time. \n\nTo verify success look for output similar to this at the end. \n\n```\n\n==========================Scores========================================\n # of classes:    2\n Accuracy:        0.7933\n Precision:       0.8064\n Recall:          0.7855\n F1 Score:        0.7514\n========================================================================\n\n```", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 46, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Error: Unrecognized option: -batchSizePerWorker\n\nSLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/opt/ibm/spark/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/opt/ibm/image-libs/spark2/tika-app-1.14.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\nUsage: spark-submit [options] <app jar | python file | R file> [app arguments]\nUsage: spark-submit --kill [submission ID] --master [spark://...]\nUsage: spark-submit --status [submission ID] --master [spark://...]\nUsage: spark-submit run-example [options] example-class [example args]\n\nOptions:\n  --master MASTER_URL         spark://host:port, mesos://host:port, yarn,\n                              k8s://https://host:port, or local (Default: local[*]).\n  --deploy-mode DEPLOY_MODE   Whether to launch the driver program locally (\"client\") or\n                              on one of the worker machines inside the cluster (\"cluster\")\n                              (Default: client).\n  --class CLASS_NAME          Your application's main class (for Java / Scala apps).\n  --name NAME                 A name of your application.\n  --jars JARS                 Comma-separated list of jars to include on the driver\n                              and executor classpaths.\n  --packages                  Comma-separated list of maven coordinates of jars to include\n                              on the driver and executor classpaths. Will search the local\n                              maven repo, then maven central and any additional remote\n                              repositories given by --repositories. The format for the\n                              coordinates should be groupId:artifactId:version.\n  --exclude-packages          Comma-separated list of groupId:artifactId, to exclude while\n                              resolving the dependencies provided in --packages to avoid\n                              dependency conflicts.\n  --repositories              Comma-separated list of additional remote repositories to\n                              search for the maven coordinates given with --packages.\n  --py-files PY_FILES         Comma-separated list of .zip, .egg, or .py files to place\n                              on the PYTHONPATH for Python apps.\n  --files FILES               Comma-separated list of files to be placed in the working\n                              directory of each executor. File paths of these files\n                              in executors can be accessed via SparkFiles.get(fileName).\n\n  --conf PROP=VALUE           Arbitrary Spark configuration property.\n  --properties-file FILE      Path to a file from which to load extra properties. If not\n                              specified, this will look for conf/spark-defaults.conf.\n\n  --driver-memory MEM         Memory for driver (e.g. 1000M, 2G) (Default: 1024M).\n  --driver-java-options       Extra Java options to pass to the driver.\n  --driver-library-path       Extra library path entries to pass to the driver.\n  --driver-class-path         Extra class path entries to pass to the driver. Note that\n                              jars added with --jars are automatically included in the\n                              classpath.\n\n  --executor-memory MEM       Memory per executor (e.g. 1000M, 2G) (Default: 1G).\n\n  --proxy-user NAME           User to impersonate when submitting the application.\n                              This argument does not work with --principal / --keytab.\n\n  --help, -h                  Show this help message and exit.\n  --verbose, -v               Print additional debug output.\n  --version,                  Print the version of current Spark.\n\n Cluster deploy mode only:\n  --driver-cores NUM          Number of cores used by the driver, only in cluster mode\n                              (Default: 1).\n\n Spark standalone or Mesos with cluster deploy mode only:\n  --supervise                 If given, restarts the driver on failure.\n  --kill SUBMISSION_ID        If given, kills the driver specified.\n  --status SUBMISSION_ID      If given, requests the status of the driver specified.\n\n Spark standalone and Mesos only:\n  --total-executor-cores NUM  Total cores for all executors.\n\n Spark standalone and YARN only:\n  --executor-cores NUM        Number of cores per executor. (Default: 1 in YARN mode,\n                              or all available cores on the worker in standalone mode)\n\n YARN-only:\n  --queue QUEUE_NAME          The YARN queue to submit to (Default: \"default\").\n  --num-executors NUM         Number of executors to launch (Default: 2).\n                              If dynamic allocation is enabled, the initial number of\n                              executors will be at least NUM.\n  --archives ARCHIVES         Comma separated list of archives to be extracted into the\n                              working directory of each executor.\n  --principal PRINCIPAL       Principal to be used to login to KDC, while running on\n                              secure HDFS.\n  --keytab KEYTAB             The full path to the file that contains the keytab for the\n                              principal specified above. This keytab will be copied to\n                              the node running the Application Master via the Secure\n                              Distributed Cache, for renewing the login tickets and the\n                              delegation tokens periodically.\n      \n"
                }
            ], 
            "source": "!$SPARK_HOME/bin/spark-submit \\\n --class skymind.dsx.KerasImportCSVSparkRunner \\\n --files sonar.csv,my_modelx.h5 \\\n --master $MASTER \\\n dl4j-snapshot.jar \\\n   -batchSizePerWorker 1 \\\n   -indexLabel 60 \\\n   -train false \\\n   -numClasses 2 \\\n   -modelFileName  my_modelx.h5 \\\n-dataFileName sonar.csv"
        }, 
        {
            "execution_count": 47, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "SLF4J: Class path contains multiple SLF4J bindings.\nSLF4J: Found binding in [jar:file:/opt/ibm/spark/jars/slf4j-log4j12-1.7.16.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: Found binding in [jar:file:/opt/ibm/image-libs/spark2/tika-app-1.14.jar!/org/slf4j/impl/StaticLoggerBinder.class]\nSLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\nSLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\nError: Master must either be yarn or start with spark, mesos, k8s, or local\nRun with --help for usage help or --verbose for debug output\n"
                }
            ], 
            "source": "!$SPARK_HOME/bin/spark-submit \\--class skymind.dsx.IrisClassifier \\--master $MASTER \\--files iris.txt \\dl4j-quickstart-1.0-SNAPSHOT-jar-with-dependencies.jar"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark", 
            "name": "python36", 
            "language": "python3"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.6.8", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}